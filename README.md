# MDITRE: Microbiome Dynamics using Interpretable Temporal Rules

[![Python](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![R](https://img.shields.io/badge/R-4.0+-blue.svg)](R/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/license-GPL--3.0-green.svg)](LICENSE)
[![Version](https://img.shields.io/badge/version-1.0.0-blue.svg)](CHANGELOG.md)

**MDITRE** (Microbiome DynamIc Time-series Rule Extraction) is a scalable and interpretable machine learning framework for predicting host status from temporal microbiome dynamics. The model learns human-readable rules that combine phylogenetic relationships and temporal patterns in longitudinal microbiome data.

## üåç Multi-Language Support

MDITRE now supports both Python and R programming languages:

- **Python** üêç - ‚úÖ **Production Ready** (v1.0.0) - Full implementation with comprehensive testing (39/39 tests passing)
- **R** üìä - ‚úÖ **Production Ready** (v1.0.0) - Complete R frontend with reticulate bridge to Python backend (37/39 tests passing)

Both implementations provide the same core functionality with language-specific APIs. The R implementation uses reticulate to bridge to the Python backend, providing seamless integration for R users. See language-specific documentation in [`Python/`](Python/) and [`R/`](R/) directories.

## ‚ú® Key Features

- üî¨ **Interpretable Rules**: Learn human-readable IF-THEN rules from microbiome time-series
- üå≥ **Phylogenetic Integration**: Leverage evolutionary relationships between microbes
- ‚è±Ô∏è **Temporal Dynamics**: Discover critical time windows and rate-of-change patterns
- üîß **Modular Architecture**: Extensible 5-layer design for easy customization
- üìä **Multiple Data Formats**: Support for 16S rRNA, shotgun metagenomics (DADA2, QIIME2, Metaphlan)
- üé® **Visualization GUI**: Interactive exploration of learned rules and patterns
- üîÅ **Reproducibility**: Deterministic seeding system (seedhash) for consistent results across Python and R
- üöÄ **Production Ready**: v1.0.0 with comprehensive test coverage and modern infrastructure
- üåê **Multi-Language**: Python and R implementations with unified functionality

## üìö Table of Contents

- [Installation](#installation)
- [Quick Start](#quick-start)
- [Architecture](#architecture)
- [Data Loading](#data-loading)
- [Training Models](#training-models)
- [Interpreting Results](#interpreting-results)
- [Development](#development)
- [Tutorials](#tutorials)
- [Advanced Usage](#advanced-usage)
- [Citation](#citation)
- [Contributing](#contributing)

---

## üîß Installation

### Requirements

- **Python Implementation**: Python 3.8+ (tested with 3.8-3.12), PyTorch 2.0+ (tested with 2.5.1, 2.6.0)
- **R Implementation**: R 4.0+ (tested with 4.5.2), reticulate, torch for R
- CUDA 11.0+ for GPU support (optional but recommended)

### Quick Install

#### Python (Backend & Standalone)

```bash
# Clone the repository
git clone https://github.com/melhzy/mditre.git
cd mditre/Python

# Install with pip (includes all dependencies)
pip install -e .

# For development (includes testing, formatting, type checking tools)
pip install -r requirements-dev.txt

# Or use Makefile:
make install-dev
```

#### R (Frontend with Python Backend)

```r
# Install from R console
# First, ensure Python MDITRE is installed (see above)

# Install R dependencies
install.packages(c("reticulate", "torch", "remotes"))

# Install seedhash for reproducible seeding
remotes::install_github("melhzy/seedhash", subdir = "R")

# Configure reticulate to use your MDITRE Python environment
library(reticulate)
use_condaenv("MDITRE")  # Or use_virtualenv() for venv

# Load R MDITRE
source("R/R/mditre_setup.R")

# Run tests to verify installation
source("R/run_mditre_tests.R")
```

### Platform-Specific Instructions (Python)

#### Ubuntu 24.04 / Linux

**With GPU Support (CUDA 12.x)**
```bash
# Create virtual environment
python3 -m venv mditre_env
source mditre_env/bin/activate

# Navigate to Python directory
cd Python/

# Install MDITRE with pinned dependencies
pip install -r requirements.txt
pip install -e .

# Or install PyTorch separately then MDITRE
pip install torch --index-url https://download.pytorch.org/whl/cu124
pip install -e .
```

**CPU Only**
```bash
python3 -m venv mditre_env
source mditre_env/bin/activate
cd Python/
pip install torch --index-url https://download.pytorch.org/whl/cpu
pip install -e .
```

#### Windows 11

**With GPU Support**
```powershell
# Using conda (recommended for Windows)
conda create -n mditre python=3.12 -y
conda activate mditre

# Navigate to Python directory
cd Python/

# Install MDITRE
pip install -r requirements.txt
pip install -e .

# Or with CUDA-specific PyTorch
pip install torch --index-url https://download.pytorch.org/whl/cu124
pip install -e .
```

#### macOS (Apple Silicon / Intel)

```bash
python3 -m venv mditre_env
source mditre_env/bin/activate

# PyTorch optimized for Apple Silicon
pip install -r requirements.txt
pip install -e .
```

### Verify Installation

```python
python -c "import mditre; import torch; print(f'MDITRE installed. PyTorch: {torch.__version__}, CUDA: {torch.cuda.is_available()}')"
```

---

## üöÄ Quick Start

### Basic Workflow (Python)

```python
from mditre.data_loader import DataLoaderRegistry, TransformPipeline
from mditre.data_loader import NormalizeTransform, FilterLowAbundance, get_otu_embeddings
from mditre.models import MDITRE
import torch

# 1. Load data (DADA2 format)
loader = DataLoaderRegistry.create_loader('16s_dada2')
data = loader.load(
    data_path='abundance.csv',
    metadata_path='metadata.csv',
    tree_path='phylogenetic_tree.jplace',
    subject_col='SubjectID',
    time_col='CollectionDay',
    label_col='Disease'
)

# 2. Preprocess data
pipeline = TransformPipeline([
    NormalizeTransform(),
    FilterLowAbundance(min_abundance=0.001, min_prevalence=0.1)
])
data['X'] = pipeline(data['X'])

# 3. Get phylogenetic embeddings
otu_embeddings = get_otu_embeddings(data['phylo_tree'], method='distance', emb_dim=10)

# 4. Create MDITRE model
model = MDITRE(
    num_rules=5,
    num_otus=data['X'].shape[1],
    num_otu_centers=10,
    num_time=data['X'].shape[2],
    num_time_centers=5,
    dist=otu_embeddings,
    emb_dim=10
)

# 5. Train
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
# ... training loop ...

# 6. Visualize rules
from mditre.visualize import visualize_rules
visualize_rules(model, data, output_dir='./results/')
```

### Basic Workflow (R)

```r
library(reticulate)

# Load R MDITRE setup (configures Python backend)
source("R/R/mditre_setup.R")

# 1. Load data through Python backend
loader <- mditre_loader$create_loader('16s_dada2')
data <- loader$load(
  data_path = 'abundance.csv',
  metadata_path = 'metadata.csv',
  tree_path = 'phylogenetic_tree.jplace',
  subject_col = 'SubjectID',
  time_col = 'CollectionDay',
  label_col = 'Disease'
)

# 2. Preprocess data
normalize <- mditre_loader$NormalizeTransform()
filter_low <- mditre_loader$FilterLowAbundance(
  min_abundance = 0.001,
  min_prevalence = 0.1
)
pipeline <- mditre_loader$TransformPipeline(list(normalize, filter_low))
data$X <- pipeline(data$X)

# 3. Get phylogenetic embeddings
otu_embeddings <- mditre_loader$get_otu_embeddings(
  data$phylo_tree,
  method = 'distance',
  emb_dim = 10L
)

# 4. Create MDITRE model
model <- mditre_models$MDITRE(
  num_rules = 5L,
  num_otus = dim(data$X)[2],
  num_otu_centers = 10L,
  num_time = dim(data$X)[3],
  num_time_centers = 5L,
  dist = otu_embeddings,
  emb_dim = 10L
)

# 5. Train model with reproducible seeding
seed_gen <- mditre_seed_generator(experiment_name = "my_experiment")
train_seed <- seed_gen$generate_seeds(1)[1]

# Set seeds for both R and PyTorch
set.seed(train_seed)
torch_py$manual_seed(as.integer(train_seed))

# ... training loop ...

# 6. Visualize rules (through Python backend)
mditre_viz <- import("mditre.visualize")
mditre_viz$visualize_rules(model, data, output_dir = './results/')
```

### What MDITRE Learns

```
Rule 1: Predicts "Healthy" (weight: 2.3)
  ‚úì Clostridiales group abundance > 7% during days 120-180
  AND
  ‚úì Bacteroides acidifaciens increasing during days 90-150

Rule 2: Predicts "Disease" (weight: -1.8)
  ‚úì Bacteroidetes abundance < 3% during days 30-90
  AND
  ‚úì Proteobacteria decreasing during days 60-120
```

---

## üèóÔ∏è Architecture

MDITRE uses a modular 5-layer architecture that mirrors biological interpretation:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Layer 1: Phylogenetic Focus                           ‚îÇ
‚îÇ  Aggregate microbes by evolutionary relationships      ‚îÇ
‚îÇ  ‚Üí SpatialAgg, SpatialAggDynamic                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Layer 2: Temporal Focus                               ‚îÇ
‚îÇ  Select important time windows                         ‚îÇ
‚îÇ  ‚Üí TimeAgg, TimeAggAbun                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Layer 3: Detector                                     ‚îÇ
‚îÇ  Apply thresholds to detect patterns                   ‚îÇ
‚îÇ  ‚Üí Threshold, Slope                                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Layer 4: Rule                                         ‚îÇ
‚îÇ  Combine detectors via logical AND                     ‚îÇ
‚îÇ  ‚Üí Rules                                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Layer 5: Classification                               ‚îÇ
‚îÇ  Weighted rule combination for prediction              ‚îÇ
‚îÇ  ‚Üí DenseLayer, DenseLayerAbun                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Repository Structure

```
mditre/
‚îú‚îÄ‚îÄ Python/                   # Python implementation (v1.0.0) ‚úÖ
‚îÇ   ‚îú‚îÄ‚îÄ mditre/              # Main package
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ core/           # Foundation (base layer, registry, math)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ layers/         # Five-layer architecture
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_loader/    # Modular data loading
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models.py       # MDITRE models
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ seeding.py      # Reproducibility
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îú‚îÄ‚îÄ tests/              # Comprehensive test suite (39 tests)
‚îÇ   ‚îú‚îÄ‚îÄ docs/               # Technical documentation
‚îÇ   ‚îú‚îÄ‚îÄ jupyter/            # Tutorials & example notebooks
‚îÇ   ‚îú‚îÄ‚îÄ mditre_outputs/     # Model outputs & results
‚îÇ   ‚îú‚îÄ‚îÄ mditre_paper_results/  # Paper reproduction code
‚îÇ   ‚îú‚îÄ‚îÄ setup.py            # Package installation
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt    # Dependencies
‚îÇ   ‚îî‚îÄ‚îÄ README.md           # Python-specific docs
‚îÇ
‚îú‚îÄ‚îÄ R/                       # R implementation (v2.0 - Coming Soon) üöß
‚îÇ   ‚îî‚îÄ‚îÄ README.md           # Planned features
‚îÇ
‚îú‚îÄ‚îÄ README.md               # This file
‚îú‚îÄ‚îÄ CHANGELOG.md            # Version history
‚îî‚îÄ‚îÄ CONTRIBUTING.md         # Contribution guidelines
```

### Python Package Structure

```
Python/mditre/
‚îú‚îÄ‚îÄ core/                      # Foundation
‚îÇ   ‚îú‚îÄ‚îÄ base_layer.py         # Abstract base class
‚îÇ   ‚îú‚îÄ‚îÄ registry.py           # Dynamic layer registration
‚îÇ   ‚îî‚îÄ‚îÄ math_utils.py         # Mathematical utilities
‚îÇ
‚îú‚îÄ‚îÄ layers/                    # Five-layer architecture
‚îÇ   ‚îú‚îÄ‚îÄ phylogenetic_focus.py # Layer 1
‚îÇ   ‚îú‚îÄ‚îÄ temporal_focus.py     # Layer 2
‚îÇ   ‚îú‚îÄ‚îÄ detector.py           # Layer 3
‚îÇ   ‚îú‚îÄ‚îÄ rule.py               # Layer 4
‚îÇ   ‚îî‚îÄ‚îÄ classification.py     # Layer 5
‚îÇ
‚îú‚îÄ‚îÄ data_loader/              # Modular data loading
‚îÇ   ‚îú‚îÄ‚îÄ base_loader.py        # Abstract loader + registry
‚îÇ   ‚îú‚îÄ‚îÄ transforms.py         # Preprocessing (7 transforms)
‚îÇ   ‚îú‚îÄ‚îÄ datasets.py           # PyTorch integration
‚îÇ   ‚îî‚îÄ‚îÄ loaders/
‚îÇ       ‚îú‚îÄ‚îÄ pickle_loader.py      # Native format
‚îÇ       ‚îî‚îÄ‚îÄ amplicon_loader.py    # 16S (DADA2, QIIME2)
‚îÇ
‚îú‚îÄ‚îÄ models.py                 # MDITRE models
‚îú‚îÄ‚îÄ seeding.py                # Reproducibility utilities
‚îú‚îÄ‚îÄ trainer.py                # Training infrastructure
‚îî‚îÄ‚îÄ visualize.py              # Visualization tools
```

**Design Benefits:**
- ‚úÖ **Multi-Language**: Python (current) + R (planned)
- ‚úÖ **Extensible**: Add new layers via registry pattern
- ‚úÖ **Interpretable**: Each layer has biological meaning
- ‚úÖ **Flexible**: Mix and match implementations
- ‚úÖ **Maintainable**: Clean separation of concerns

---

## üìä Data Loading

### Supported Formats

| Format | Loader | Description |
|--------|--------|-------------|
| **DADA2** | `16s_dada2` | 16S amplicon sequencing (abundance + tree) |
| **QIIME2** | `16s_qiime2` | QIIME2 artifacts (table.qza + tree.qza) |
| **Pickle** | `pickle` | Native MDITRE format |
| **Trajectory** | `pickle_trajectory` | Variable-length time series |

### Loading Examples

#### DADA2 Output

```python
from mditre.data_loader import DataLoaderRegistry

loader = DataLoaderRegistry.create_loader('16s_dada2')
data = loader.load(
    data_path='abundance.csv',
    metadata_path='sample_metadata.csv',
    tree_path='placement.jplace',
    subject_col='SubjectID',
    time_col='CollectionDay',
    label_col='Disease'
)

print(f"Shape: {data['X'].shape}")  # (subjects, OTUs, timepoints)
```

#### QIIME2 Artifacts

```python
loader = DataLoaderRegistry.create_loader('16s_qiime2')
data = loader.load(
    feature_table_path='table.qza',
    metadata_path='metadata.tsv',
    tree_path='tree.qza',
    subject_col='subject_id',
    time_col='days',
    label_col='diagnosis'
)
```

#### Native Pickle

```python
loader = DataLoaderRegistry.create_loader('pickle')
data = loader.load('preprocessed_data.pkl')
```

### Data Preprocessing

Composable transformation pipeline:

```python
from mditre.data_loader import (
    TransformPipeline,
    NormalizeTransform,      # Sum to 1 per sample
    FilterLowAbundance,      # Remove rare OTUs
    CLRTransform,            # Centered log-ratio
    LogTransform,            # Log with pseudocount
    ZScoreTransform          # Z-score standardization
)

pipeline = TransformPipeline([
    NormalizeTransform(),
    FilterLowAbundance(min_abundance=0.001, min_prevalence=0.1),
    CLRTransform(pseudocount=0.5)
])

X_transformed = pipeline(data['X'])
```

### PyTorch DataLoaders

Create train/val/test splits:

```python
from mditre.data_loader import create_stratified_loaders

loaders = create_stratified_loaders(
    X=data['X'],
    y=data['y'],
    mask=data['mask'],
    train_size=0.7,
    val_size=0.15,
    test_size=0.15,
    batch_size=16,
    random_state=42
)

for batch in loaders['train']:
    data_batch = batch['data']      # (batch, OTUs, time)
    labels_batch = batch['label']   # (batch,)
    mask_batch = batch['mask']      # (batch, time)
```

### Adding Custom Loaders

```python
from mditre.data_loader import BaseDataLoader, DataLoaderRegistry

@DataLoaderRegistry.register('my_format')
class MyLoader(BaseDataLoader):
    def load(self, data_path, **kwargs):
        X = load_my_data(data_path)  # Your loading logic
        return {
            'X': X,    # (subjects, OTUs, timepoints)
            'y': y,    # (subjects,)
            'mask': mask,
            'phylo_tree': tree,
            'metadata': metadata
        }
```

---

## üéØ Training Models

### Configuration File

Create `config.cfg`:

```ini
[Paths]
data_dir = /path/to/data
output_dir = /path/to/output

[Data]
abundance_file = abundance.csv
metadata_file = metadata.csv
tree_file = tree.nwk

[Model]
num_rules = 5
num_otu_centers = 10
num_time_centers = 5
embedding_dim = 10

[Training]
epochs = 2000
batch_size = 32
learning_rate = 0.001
num_folds = 5
```

Run training:
```bash
python mditre/tutorials/model_run_tutorial.py --data config.cfg
```

### Python API

```python
from mditre.models import MDITRE
import torch

model = MDITRE(
    num_rules=5,
    num_otus=100,
    num_otu_centers=10,
    num_time=15,
    num_time_centers=5,
    dist=otu_embeddings,
    emb_dim=10
)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = model.to(device)

optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
criterion = torch.nn.BCEWithLogitsLoss()

for epoch in range(epochs):
    for batch in train_loader:
        optimizer.zero_grad()
        outputs = model(batch['data'].to(device), mask=batch['mask'].to(device))
        loss = criterion(outputs, batch['label'].float().to(device))
        loss.backward()
        optimizer.step()
```

### Hyperparameter Guidelines

| Dataset Size | `num_rules` | `num_otu_centers` | `num_time_centers` | `epochs` | `batch_size` |
|--------------|-------------|-------------------|-------------------|----------|--------------|
| **Small** (<50) | 3 | 5 | 3 | 2000 | 16 |
| **Medium** (50-200) | 5 | 10 | 5 | 3000 | 32 |
| **Large** (>200) | 7-10 | 15-20 | 7-10 | 5000 | 64 |

---

## üîç Interpreting Results

### Rule Structure

Each MDITRE rule contains:

1. **Phylogenetic Group**: Which microbes (e.g., Clostridiales)
2. **Time Window**: When to look (e.g., days 120-180)
3. **Detector Type**: Abundance or slope threshold
4. **Threshold**: Significance cutoff (e.g., > 7%)
5. **Weight**: Contribution to prediction

### Visualization GUI

```python
from mditre.visualize import visualize_rules

visualize_rules(
    model=trained_model,
    data=data,
    output_dir='./results/'
)
```

**Features:**
- View all learned rules
- Explore which subjects activate each rule
- Examine phylogenetic groupings
- Analyze temporal patterns
- Export rule summaries

### Example Rule Interpretation

```
Rule 1: Predicts "Preterm Birth Risk" (weight: 2.1)

Detector 1: Phylogenetic Focus
  - Microbes: Lactobacillus spp. (OTUs 12, 15, 23, 31)
  - Time: Weeks 20-28 of pregnancy
  - Type: Abundance threshold
  - Condition: < 15%
  - Meaning: Low Lactobacillus in mid-pregnancy

Detector 2: Phylogenetic Focus  
  - Microbes: Gardnerella vaginalis cluster
  - Time: Weeks 24-32
  - Type: Slope (rate of change)
  - Condition: Increasing (positive slope)
  - Meaning: Rising Gardnerella levels

Combined Rule:
  IF (Lactobacillus < 15% at weeks 20-28) AND 
     (Gardnerella increasing at weeks 24-32)
  THEN: Predict High Preterm Birth Risk
```

---

## üìñ Tutorials

### Tutorial 1: 16S rRNA Analysis
**[Tutorial_Bokulich_16S_data.ipynb](jupyter/tutorials/Tutorial_Bokulich_16S_data.ipynb)**

- Load 16S amplicon data (DADA2)
- Build phylogenetic trees
- Train model to predict infant diet
- Interpret rules with GUI

**Dataset:** Bokulich et al. infant gut microbiome (2016)

### Tutorial 2: Shotgun Metagenomics
**[Tutorial_2_metaphlan_data.ipynb](jupyter/tutorials/Tutorial_2_metaphlan_data.ipynb)**

- Work with MetaPhlAn profiles
- Handle shotgun metagenomic data
- Process taxonomic hierarchies

### Tutorial 3: Complete Workflow
**[Tutorial_1_16s_data.ipynb](jupyter/tutorials/Tutorial_1_16s_data.ipynb)**

- DADA2 sequence processing
- Phylogenetic placement (pplacer)
- Data QC and preprocessing
- Hyperparameter tuning
- Rule visualization

---

## üî¨ Advanced Usage

### K-Fold Cross-Validation

```python
from mditre.data_loader import create_kfold_loaders

kfold_loaders = create_kfold_loaders(
    X=data['X'], y=data['y'], mask=data['mask'],
    n_splits=5, batch_size=16, random_state=42
)

results = []
for fold_idx, train_loader, val_loader in kfold_loaders:
    model = MDITRE(...)  # Fresh model per fold
    # Train and evaluate
    fold_result = train_and_evaluate(model, train_loader, val_loader)
    results.append(fold_result)

print(f"Average AUC: {np.mean([r['auc'] for r in results]):.3f}")
```

### Phylogenetic Embeddings

```python
from mditre.data_loader import get_otu_embeddings, compute_phylo_distance_matrix
from ete3 import Tree

tree = Tree("tree.nwk")

# Method 1: Distance-based (recommended)
embeddings = get_otu_embeddings(tree, method='distance', emb_dim=10)

# Method 2: MDS on distance matrix
dist_matrix = compute_phylo_distance_matrix(tree)
embeddings = get_otu_embeddings(tree, method='mds', emb_dim=10, 
                                dist_matrix=dist_matrix)

# Method 3: Random baseline
embeddings = get_otu_embeddings(tree, method='random', emb_dim=10, seed=42)
```

### Custom Layer Implementation

```python
from mditre.core import BaseLayer, LayerRegistry

@LayerRegistry.register('phylogenetic_focus', 'custom')
class CustomSpatialAgg(BaseLayer):
    def __init__(self, num_rules, emb_dim, num_otus):
        super().__init__()
        # Your initialization
    
    def forward(self, x):
        # Your forward logic
        return x_aggregated
    
    def init_params(self, init_args):
        # Parameter initialization
        pass
```

---

## üéØ Use Cases

### 1. Disease Onset Prediction
```python
# Example: Type 1 diabetes risk from infant gut microbiome
# - Monthly samples over 3 years
# - Identifies: Pre-disease microbial changes, critical time windows
```

### 2. Dietary Intervention Classification
```python
# Example: Distinguish diet types from microbiome
# - Samples before/during/after diet change
# - Reveals: Responsive microbes, adaptation speed
```

### 3. Clinical Outcome Prediction
```python
# Example: Preterm birth from vaginal microbiome
# - Weekly pregnancy samples
# - Discovers: Early warning signals, dysbiotic patterns
```

---

## üêõ Troubleshooting

### Common Issues

**CUDA out of memory:**
```bash
python script.py --batch-size 16 --device cpu
```

**Slow training:**
- Use GPU acceleration
- Reduce complexity (`num_rules`, `num_otu_centers`)
- Increase batch size if memory allows

**Poor performance:**
- Increase `epochs`
- Adjust learning rate (try 0.01, 0.001, 0.0001)
- Check data quality and class balance

### Package Validation

```bash
python validate_package.py
```

Expected:
```
================================================================================
ALL TESTS PASSED [OK]
================================================================================

[PASS] Core module
[PASS] Layers module
[PASS] Data loader module
[PASS] Models module
[PASS] Complete integration
[PASS] Backward compatibility
```

---

## üìà Performance

| Dataset | Subjects | Timepoints | OTUs | Training Time* | Memory |
|---------|----------|------------|------|----------------|--------|
| Small | <50 | 5-15 | 50-200 | 5-10 min | 2 GB |
| Medium | 50-200 | 10-20 | 100-500 | 20-40 min | 4 GB |
| Large | >200 | 15-30 | 200-1000 | 1-3 hours | 8 GB |

*NVIDIA RTX 3090 GPU, ~3000 epochs

**Optimization:**
- Use GPU: 10-50x speedup
- Larger batch sizes (if memory allows)
- Early stopping on validation loss
- Mixed precision training (`torch.cuda.amp`)

---

## üìù Data Format

### Required Structure

1. **Abundance Table**: (samples √ó OTUs) with counts/relative abundances
2. **Metadata**: Subject IDs, timepoints, binary labels
3. **Phylogenetic Tree**: Newick format or distance matrix

### Example

```python
import pandas as pd

# Abundance
abundance_df = pd.DataFrame({
    'OTU1': [0.10, 0.15, 0.08, ...],
    'OTU2': [0.05, 0.03, 0.12, ...],
})

# Metadata
metadata_df = pd.DataFrame({
    'subject_id': ['S1', 'S1', 'S2', ...],
    'timepoint': [0, 30, 0, ...],
    'label': [0, 0, 1, ...]
})

# Tree (Newick)
tree_file = "tree.nwk"
```

---

## üõ†Ô∏è Development

### For Contributors

MDITRE v1.0.0 includes modern development infrastructure for easy contribution.

#### Quick Development Setup

```bash
# Clone and setup
git clone https://github.com/melhzy/mditre.git
cd mditre

# Install development dependencies
make install-dev
# Or: pip install -r requirements-dev.txt

# Run tests
make test

# Format code
make format

# Check code quality
make quality
```

#### Development Commands

| Command | Description |
|---------|-------------|
| `make install` | Install package in editable mode |
| `make install-dev` | Install with development tools |
| `make test` | Run all tests (pytest) |
| `make test-cov` | Run tests with coverage report |
| `make test-fast` | Skip slow tests |
| `make format` | Format code (black + isort) |
| `make lint` | Check code style (flake8) |
| `make typecheck` | Run type checker (mypy) |
| `make quality` | Run all quality checks |
| `make dev` | Quick dev cycle (format + fast test) |
| `make ci` | Full CI simulation |
| `make clean` | Remove build artifacts |

#### Running Tests

```bash
# All tests
pytest tests/ -v

# Specific test file
pytest tests/test_mditre_comprehensive.py -v

# With coverage
pytest tests/ --cov=mditre --cov-report=html

# By marker
pytest tests/ -m architecture
pytest tests/ -m "not slow"

# Latest: 28/28 passing in 2.17s ‚úÖ
```

#### Project Structure

```
mditre/
‚îú‚îÄ‚îÄ .gitignore              # Version control config
‚îú‚îÄ‚îÄ pyproject.toml          # Modern packaging (PEP 518)
‚îú‚îÄ‚îÄ requirements.txt        # Pinned dependencies
‚îú‚îÄ‚îÄ requirements-dev.txt    # Development tools
‚îú‚îÄ‚îÄ Makefile                # Task automation
‚îú‚îÄ‚îÄ CHANGELOG.md            # Version history
‚îú‚îÄ‚îÄ CONTRIBUTING.md         # Contribution guidelines
‚îú‚îÄ‚îÄ tests/                  # Test suite
‚îÇ   ‚îú‚îÄ‚îÄ conftest.py         # Shared fixtures
‚îÇ   ‚îú‚îÄ‚îÄ test_*.py           # Test files
‚îÇ   ‚îî‚îÄ‚îÄ README.md           # Test documentation
‚îú‚îÄ‚îÄ mditre/                 # Package source
‚îî‚îÄ‚îÄ docs/                   # Documentation
```

#### Code Style

- **Formatter**: Black (100 char line length)
- **Import Sort**: isort (black profile)
- **Linter**: Flake8
- **Type Checker**: mypy
- **All configured in**: `pyproject.toml`

#### Quality Standards

- ‚úÖ All tests must pass
- ‚úÖ Code coverage >80%
- ‚úÖ Black formatted
- ‚úÖ No linting errors
- ‚úÖ Type hints for public APIs
- ‚úÖ Docstrings (Google style)

See [CONTRIBUTING.md](CONTRIBUTING.md) for detailed guidelines.

---

## ü§ù Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for:

- üöÄ Getting started guide
- üìã Contribution workflow
- ‚úÖ Code quality standards
- üìù Documentation guidelines
- üêõ Bug report templates
- ‚ú® Feature request process

### Quick Contribution Guide

1. **Fork** the repository
2. **Create** a feature branch
3. **Make** your changes
4. **Test**: `make test`
5. **Format**: `make format`
6. **Quality Check**: `make quality`
7. **Commit** with clear message
8. **Push** and create Pull Request

### Areas for Contribution

- üêõ Bug fixes
- ‚ú® New features (layers, loaders, transforms)
- üìù Documentation improvements
- üß™ Additional tests
- üé® Visualization enhancements
- üìä Example notebooks

---

## üìñ Documentation

### Core Documentation
- **[README.md](README.md)** - This file: Installation, usage, quick start
- **[QA.md](QA.md)** - Quality assurance and test status
- **[CHANGELOG.md](CHANGELOG.md)** - Version history and changes
- **[CONTRIBUTING.md](CONTRIBUTING.md)** - Contribution guidelines

### Technical Documentation (`docs/`)
- **[docs/README.md](docs/README.md)** - Documentation index and navigation
- **[docs/MODULAR_ARCHITECTURE.md](docs/MODULAR_ARCHITECTURE.md)** - 5-layer architecture reference
- **[docs/DATA_LOADER_GUIDE.md](docs/DATA_LOADER_GUIDE.md)** - Data loading system API
- **[docs/DEVELOPMENT.md](docs/DEVELOPMENT.md)** - Development guide & performance
- **[docs/SEEDING_GUIDE.md](docs/SEEDING_GUIDE.md)** - Reproducibility & seeding
- **[docs/TRAINER_FIXES.md](docs/TRAINER_FIXES.md)** - Bug fixes documentation

### Examples & Tutorials
- **Examples**: `mditre/examples/` - Working code examples
- **Tutorials**: `jupyter/` - Jupyter notebooks with step-by-step guides
- **Quick Test**: `jupyter/run_mditre_test.ipynb` - Fast training demo

### Getting Help
- **Issues**: [GitHub Issues](https://github.com/melhzy/mditre/issues)
- **Discussions**: [GitHub Discussions](https://github.com/melhzy/mditre/discussions)
- **Tests**: `tests/` - Comprehensive test suite documentation

---

## üìÑ Citation

If you use MDITRE, please cite:

```bibtex
@article{maringanti2022mditre,
  title={MDITRE: Scalable and Interpretable Machine Learning for Predicting Host Status from Temporal Microbiome Dynamics},
  author={Maringanti, Veda Sheersh and Bucci, Vanni and Gerber, Georg K},
  journal={mSystems},
  volume={7},
  number={3},
  pages={e00132--22},
  year={2022},
  publisher={American Society for Microbiology},
  doi={10.1128/msystems.00132-22}
}
```

**Paper:** Maringanti VS, Bucci V, Gerber GK. 2022. MDITRE: Scalable and Interpretable Machine Learning for Predicting Host Status from Temporal Microbiome Dynamics. mSystems 7:e00132-22. https://doi.org/10.1128/msystems.00132-22

---

## üìú License

GNU General Public License v3.0 (GPL-3.0) - see [LICENSE](LICENSE) file

---

## üë• Contributors

- **Venkata Suhas Maringanti** - Original implementation
- **Georg K. Gerber** - Principal Investigator  
- **Vanni Bucci** - Co-Principal Investigator
- **Ziyuan Huang** - Maintainer, v1.0.0 infrastructure improvements

---

## üôè Acknowledgments

We thank the microbiome research community for public data and the developers of PyTorch, scikit-learn, and other open-source tools.

---

## üìå Version History

See [CHANGELOG.md](CHANGELOG.md) for detailed version history.

- **v1.0.0** (November 2025): Production release with modern infrastructure
  - Modular 5-layer architecture
  - Extensible data loading system
  - Deterministic seeding module
  - Comprehensive test suite (28 tests, 100% passing)
  - Modern development tools (pyproject.toml, Makefile, requirements.txt)
  - Documentation reorganization (9 docs ‚Üí 6 focused guides)
  - Deprecation warnings for legacy code
  - Task automation with 20+ Makefile commands
- **v0.1.6** (2022): Initial beta release

---

**üéâ MDITRE v1.0.0 is production-ready with modern development infrastructure!**

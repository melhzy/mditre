% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/layer4_rule.R
\name{rule_layer}
\alias{rule_layer}
\title{Rules Layer}
\usage{
rule_layer(num_rules, num_otus, num_time_centers, layer_name = "rules", ...)
}
\arguments{
\item{num_rules}{Number of rules}

\item{num_otus}{Number of OTUs (detectors per rule)}

\item{num_time_centers}{Number of time centers (unused, kept for compatibility)}

\item{layer_name}{Name for this layer instance (default: "rules")}

\item{...}{Additional arguments passed to base layer}
}
\value{
An R6 class representing a Rules layer
}
\description{
Combine detector responses using approximate logical AND. Uses binary concrete
relaxation to select which detectors contribute to each rule, then approximates
AND operation via product.
}
\details{
Architecture:
\itemize{
\item Input: (batch, num_rules, num_otus)
\item Output: (batch, num_rules)
}

The layer implements a differentiable approximation of logical AND:
\deqn{AND(x_1, x_2, ..., x_n) \approx \prod_i (1 - \alpha_i(1 - x_i))}

where \eqn{\alpha_i} are learned binary selection variables (via binary concrete)
that determine which detectors contribute to each rule.

\strong{Binary Concrete}: Uses Gumbel-Softmax trick for differentiable binary selection:
\itemize{
\item During training: Samples from Gumbel distribution for stochasticity
\item During inference: Deterministic selection based on learned probabilities
\item Optional hard mode: Straight-through estimator for discrete selection
}

\strong{Interpretability}: After training, the learned \eqn{\alpha} values indicate
which OTUs/microbes are important for each rule, enabling biological interpretation.
}
\examples{
\dontrun{
library(torch)

# Create rules layer
layer <- rule_layer(
  num_rules = 5,
  num_otus = 20,
  num_time_centers = 1
)

# Forward pass
x <- torch_rand(32, 5, 20)  # batch=32, rules=5, otus=20
output <- layer(x)
print(output$shape)  # [32, 5]

# Training mode with noise
layer$train()
output_train <- layer(x, k = 1.0, hard = FALSE, use_noise = TRUE)

# Evaluation mode (deterministic)
layer$eval()
output_eval <- layer(x, k = 1.0, hard = TRUE, use_noise = FALSE)

# Inspect learned selections
alpha_probs <- torch_sigmoid(layer$alpha)
print(alpha_probs)  # Which OTUs are selected for each rule
}

}
